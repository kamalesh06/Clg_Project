{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxD5nvN1a85osHhATxICeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamalesh06/Clg_Project/blob/main/untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit openai-whisper TTS transformers opennmt-py torch torchaudio soundfile"
      ],
      "metadata": {
        "id": "nf1dqx0f8E0e",
        "outputId": "ae6bff37-95d6-40e6-ba95-c9229bda6144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.43.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting opennmt-py\n",
            "  Downloading OpenNMT_py-3.5.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.13)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.0)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.7)\n",
            "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.10.0)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCpQWmhu4XNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893db9dd-5918-46e8-a1a1-3125a4a445d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import whisper\n",
        "from TTS.api import TTS\n",
        "import sqlite3\n",
        "import os\n",
        "import torchaudio\n",
        "import torch\n",
        "import tempfile\n",
        "import soundfile as sf\n",
        "from together import Together\n",
        "import re\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "# Load Whisper model for Speech-to-Text\n",
        "@st.cache_resource\n",
        "def load_whisper_model():\n",
        "    return whisper.load_model(\"small\")\n",
        "\n",
        "# Load Coqui TTS for Text-to-Speech\n",
        "@st.cache_resource\n",
        "def load_coqui_tts():\n",
        "    return TTS(model_name = \"tts_models/multilingual/multi-dataset/your_tts\", progress_bar = False)\n",
        "\n",
        "# Initialize SQLite database for storing interactions\n",
        "def init_db():\n",
        "    conn = sqlite3.connect('mahabalipuram.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('''CREATE TABLE IF NOT EXISTS interactions\n",
        "                 (id INTEGER PRIMARY KEY, user_input TEXT, bot_response TEXT, language TEXT)''')\n",
        "    conn.commit()\n",
        "    return conn, c\n",
        "\n",
        "# Generate bot response using DeepSeek API\n",
        "def generate_response(user_input):\n",
        "\n",
        "    try:\n",
        "            # Replace with your API keys\n",
        "        together_api = \"5905f15b1de0cfa5e6283bcc7fa1de67b51ad6dc51acb618de83be3bdff2486b\"\n",
        "        client = Together(api_key = together_api)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\",\n",
        "            messages = [{\"role\": \"user\", \"content\": user_input}],\n",
        "            max_tokens = None,\n",
        "            temperature = 0.7,\n",
        "            top_p = 0.7,\n",
        "            top_k = 50,\n",
        "            repetition_penalty = 1,\n",
        "            stream = False\n",
        "            )\n",
        "\n",
        "        # Check if the response contains the expected data\n",
        "        if hasattr(response, \"choices\") and response.choices:\n",
        "        # Extract response text\n",
        "            raw_response = response.choices[0].message.content\n",
        "\n",
        "            # Remove the <think> block using regex\n",
        "            cleaned_response = re.sub(r\"<think>.*?</think>\", \"\", raw_response, flags = re.DOTALL).strip()\n",
        "            return cleaned_response\n",
        "        else:\n",
        "            print(\"Error: No response choices found.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Convert audio frame to text using Whisper\n",
        "def process_audio(audio_file, whisper_model):\n",
        "    audio, sr = sf.read(audio_file)\n",
        "\n",
        "    # Ensure correct sample rate using torchaudio\n",
        "    target_sr = 16000\n",
        "    waveform = torch.tensor(audio).float()\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq = sr, new_freq = target_sr)\n",
        "    resampled_audio = resampler(waveform).numpy()\n",
        "\n",
        "    # Save resampled audio to temporary file using 'soundfile'\n",
        "    with tempfile.NamedTemporaryFile(delete = False, suffix = \".wav\") as tmp_audio:\n",
        "        sf.write(tmp_audio.name, resampled_audio, target_sr)\n",
        "        audio_file = tmp_audio.name\n",
        "\n",
        "    # Transcribe with Whisper\n",
        "    result = whisper_model.transcribe(audio_file)\n",
        "    os.remove(audio_file)  # Cleanup\n",
        "    return result[\"text\"]\n",
        "\n",
        "def main():\n",
        "    st.title(\"Mahabalipuram AI Voice Bot\")\n",
        "\n",
        "    st.write(\"Welcome to the Mahabalipuram Heritage Assistant! Speak into your microphone or upload an audio file.\")\n",
        "\n",
        "    # Language selection\n",
        "    language = st.selectbox(\"Select Language\", [\"English\", \"Tamil\", \"Hindi\"])\n",
        "\n",
        "    # Audio input\n",
        "    st.write(\"### Record a voice message\")\n",
        "    audio_file = st.audio_input(\"Record a voice message\")\n",
        "\n",
        "    # Load models and database\n",
        "    whisper_model = load_whisper_model()\n",
        "    tts = load_coqui_tts()\n",
        "    conn, cursor = init_db()\n",
        "\n",
        "    if audio_file:\n",
        "        st.write(\"Processing audio...\")\n",
        "        try:\n",
        "            user_input = process_audio(audio_file, whisper_model)\n",
        "            st.write(f\"**You said:** {user_input}\")\n",
        "\n",
        "            bot_response = generate_response(user_input)\n",
        "            st.write(f\"**Bot Response (English):** {bot_response}\")\n",
        "\n",
        "            # Store interaction in the database\n",
        "            cursor.execute(\"INSERT INTO interactions (user_input, bot_response, language) VALUES (?, ?, ?)\", (user_input, bot_response, language))\n",
        "            conn.commit()\n",
        "\n",
        "            # Convert response to speech\n",
        "            with tempfile.NamedTemporaryFile(delete = False, suffix = \".wav\") as tmp_audio:\n",
        "                tts.tts_to_file(text = bot_response,speaker = 'female-en-5',language = 'en', file_path = tmp_audio.name)\n",
        "                audio_file = tmp_audio.name\n",
        "\n",
        "            st.audio(audio_file)\n",
        "\n",
        "            # Defer deletion of audio file until next session state reset\n",
        "            st.session_state[\"last_audio_file\"] = audio_file\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run main.py"
      ],
      "metadata": {
        "id": "NDkqtpDv7G3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}